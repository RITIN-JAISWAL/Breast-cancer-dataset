{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "614080eef877a8cc3f436522abe889a14958d4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "breast_cancer = pd.read_csv('C:\\\\Users\\\\RITIN JAISWAL\\\\Desktop\\\\Stock market prediction\\\\Breast cancer\\\\Breast-cancer-dataset\\\\breast_cancer_data.csv')\n",
    "# Dataset Shape\n",
    "print (breast_cancer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Few Columns and Head Details\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a06977de599e1a2094e6d0b74f7e0c7ceef02165"
   },
   "source": [
    "<p> We need to remove the features which should be excluded, e.g. ID. We also need to specify the target feature, i.e. diagnosis class.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "438a3421517af2feab182ceca38e2396bb10f05e"
   },
   "outputs": [],
   "source": [
    "# Features \"id\" and \"Unnamed: 32\" should be removed\n",
    "feature_names = breast_cancer.columns[2:-1]\n",
    "X = breast_cancer[feature_names]\n",
    "# the target feature, i.e. diagnosis class\n",
    "y = breast_cancer.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed083f7eaec1b4389b74fca255d68bc9930ab23b"
   },
   "source": [
    "<p>The traget feature in this dataset is included as a text value so it should be converted into a numerical value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4a9999cf49909c36cc65261cd345776b02a407b6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "# M -> 1 and B -> 0\n",
    "y = class_le.fit_transform(breast_cancer.diagnosis.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data preperation.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for training data: 0.904\n",
      "acc for test data: 0.909\n",
      "MLP Classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        90\n",
      "           1       0.95      0.79      0.87        53\n",
      "\n",
      "    accuracy                           0.91       143\n",
      "   macro avg       0.92      0.89      0.90       143\n",
      "weighted avg       0.91      0.91      0.91       143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ritin jaiswal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0, activation='logistic', solver='adam', hidden_layer_sizes=(10,), max_iter=100)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predict = clf.predict(X_test)\n",
    "\n",
    "# Accuracy factors\n",
    "print('acc for training data: {:.3f}'.format(clf.score(X_train, y_train)))\n",
    "print('acc for test data: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "print('MLP Classification report:\\n\\n', classification_report(y_test, clf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ritin jaiswal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:568: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP  (hidden layer sizes=10): ROC AUC=0.956\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3wV1b338c+PEAQ1AgIqJXI7UgFFUKJQrXipVRDrpVpBOZwXKgcvQG09tvIcz2Or9mIfbeuN1gfBon04UsUbXlrUUyg9IgVCw00LJyJIEF9CREQxmpDf88dM4jbsJBOyZ2+S+b5fr/3Knpk1M78JYf/2WrNmLXN3REQkudrkOgAREcktJQIRkYRTIhARSTglAhGRhFMiEBFJuLa5DqCpunbt6r179851GCIiLUpxcfEOd++WbluLSwS9e/dmxYoVuQ5DRKRFMbPN9W1T05CISMIpEYiIJJwSgYhIwikRiIgknBKBiEjCxZYIzOwRM3vfzNbWs93M7H4zKzWz1WZ2UlyxiIhI/eKsEcwGRjawfRTQL3xNAn4bYywiLU7x5p1MX1hK8eaduQ5FDgBx/j3E9hyBuy82s94NFLkIeMyDcbCXmlknM+vu7tviikmkpSjevJOxM16ncq/TxqD/UQUUtM/PdViSI7srKvnHe7txh4Py2zBn4nCG9uqcsePn8h5BD2BLynJZuG4fZjbJzFaY2Yrt27dnJTiRXFq6sZzKvcFcIdUOH1VU5TgiyaWPKqqodnCgsqqapRvLM3r8XD5ZbGnWpZ0lx91nADMAioqKNJOOtHrD+3ahjQVJoH1+G+4be2JGvwFKy1K8eSfjZi6lsqqa/LZtGN63S0aPn8tEUAYcnbJcCLybo1hEDihDe3Wm/1EFfFRRpSQgDO3VmTkTh7N0YznD+3bJ+N9DLhPBfGCKmc0FhgG7dH9A5AsF7fMpaJ+vJCBAkAzi+luILRGY2ePAmUBXMysDfgTkA7j7Q8BLwPlAKbAHuCquWEREpH5x9hq6opHtDkyO6/wiIhKNniyWxGhp/fJ3V1Sy9cNPW0y80nK1uPkIRPZHS+uXv7uikje27QZg3MylGe83LpJKNQJJhJbWLz81vjj6jYukUo0goYo374ytK9qBaHjfLhjBgyrt2h74/fLj7jcukkqJIIFaWjNJJuyuqPziaUU/8J9JjLvfuEgqJYIEStdM0toTQWpTy95qZ+nG8gP+wzXOfuMiqZQIEiiJwxeoqUWkfkoErUBT2/uH9upMz8MP5oNPPmfaqAGtPgmAmlpEGqJE0MLtT3v/7opKNpXvAeCOF9Zx7FEFifhgVFOLSHrqPtrC7U+3SHVNFJFUqhG0cPvT3q/2chFJpUSQY83tz78/7f1qLxeRVEoEOZSJ/vz7296v9nIRqaF7BDmUiWEP1N4vIs2lGkEOZaI/v9r7RaS5lAjI3bg7mejPr/Z+EWmuxCeCXI67k6n+/GrvF5HmSPw9glwOT6z2fRE5ECS+RpDLcXfUvi8iB4LEJ4KhvTrT/6gCPqqoyvrga2rfF5EDQeITAUBB+3wK2ufn5INY7fsikmuJv0cgIpJ0SgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCIiCRdrIjCzkWa23sxKzWxamu0dzex5M1tlZuvM7Ko44xERkX3FlgjMLA+YDowCBgJXmNnAOsUmA2+4+2DgTOCXZtYurphERGRfcdYITgFK3X2ju38OzAUuqlPGgQIzM+BQ4AMgexMCiIhIrImgB7AlZbksXJfqQWAA8C6wBrjR3avrHsjMJpnZCjNbsX379rjiFRFJpDgTgaVZ53WWzwNKgK8AQ4AHzeywfXZyn+HuRe5e1K1bt8xHKiKSYHEmgjLg6JTlQoJv/qmuAp72QCnwNtA/xphERKSOOBPBcqCfmfUJbwCPBebXKfMO8A0AMzsSOBbYGGNMIiJSR2wzlLl7lZlNARYAecAj7r7OzK4Ltz8E3AnMNrM1BE1Jt7j7jrhiEhGRfcU6VaW7vwS8VGfdQynv3wXOjTMGERFpmJ4sFhFJOCUCEZGEUyIQEUk4JQIRkYRTIhARSTglAhGRhFMiEBFJOCUCEZGEi/WBsgNZ8eadLN1YzvC+XdhdUclHFVUUb97J0F6dcx2aiEhWJTIRFG/eydgZr1O51zG+GBJ13MylzJk4XMlARBIlctOQmR0SZyDZtHRjOZV7g4//1HGxK6uqWbqxPDdBiYjkSKOJwMxONbM3gDfD5cFm9pvYI4vR8L5daBPOltAuz2jXtg15Bvlt2zC8b5fcBicikmVRmoZ+TTCBzHwAd19lZiNijSpmQ3t1pv9RBXxUUcV9Y08EqL1foGYhEUmaSPcI3H1LMK1wrb3xhJM9Be3zKWifX/vBrwQgIkkVJRFsMbNTAQ8nmPkuYTORiIi0fFFuFl8HTCaYeL6MYG7hG+IMSkREsidKjeBYdx+XusLMTgNeiyckERHJpig1ggcirhMRkRao3hqBmX0NOBXoZmY3pWw6jGAOYhERaQUaahpqBxwalilIWf8RcFmcQYmISPbUmwjc/S/AX8xstrtvzmJMIiKSRVFuFu8xs7uB44D2NSvd/ezYohIRkayJcrN4DvAPoA9wO7AJWB5jTCIikkVREkEXd58FVLr7X9z9amB4zHFlXPHmnUxfWErx5p0A7K6oZOuHn9Yui4gkVZSmocrw5zYzGw28CxTGF1LmpQ473cag5+EHs6l8D6Chp0VEotQIfmJmHYF/A24GZgLfizWqDEsddrra4YNPPq/dpqGnRSTpGk0E7v6Cu+9y97Xufpa7DwU+yEJsGZM67HT7/DZMGzWA9vkaelpEBBp+oCwPuJxgjKE/uftaM7sA+HegA3BidkJsvrrDTg/t1ZljjyrQ0NMiIjR8j2AWcDSwDLjfzDYDXwOmufuz2Qguk9INO60EICLScCIoAk5w92ozaw/sAI5x9/eyE5qIiGRDQ/cIPnf3agB3rwA2NDUJmNlIM1tvZqVmNq2eMmeaWYmZrTOzvzTl+CIi0nwN1Qj6m9nq8L0B/xQuG+DufkJDBw7vMUwHvkkwj8FyM5vv7m+klOkE/AYY6e7vmNkRzbgWERHZDw0lggHNPPYpQKm7bwQws7nARcAbKWWuBJ5293cA3P39Zp5TRESaqKFB55o70FwPYEvKchkwrE6ZrwL5ZraIYITT+9z9sboHMrNJwCSAnj17NjMsERFJFeWBsv1ladZ5neW2wFBgNHAe8L/N7Kv77OQ+w92L3L2oW7dumY9URCTBogwxsb/KCLqf1igkGJ6ibpkd7v4J8ImZLQYGAxtijEtERFJEqhGYWQczO7aJx14O9DOzPmbWDhgLzK9T5jngdDNra2YHEzQdvdnE84iISDM0mgjM7FtACfCncHmImdX9QN+Hu1cBU4AFBB/uT7j7OjO7zsyuC8u8GR53NcGDazPdfe3+XoyIiDRdlKahHxP0AFoE4O4lZtY7ysHd/SXgpTrrHqqzfDdwd5TjiYhI5kVpGqpy912xRyIiIjkRpUaw1syuBPLMrB/wXWBJvGGJiEi2RKkRTCWYr/gz4D+BXbSw+QhERKR+UWoEx7r7rcCtcQcjIiLZF6VG8Csz+4eZ3Wlmx8UekYiIZFWUGcrOAs4EtgMzzGyNmf1H3IGJiEh2RHqgzN3fc/f7gesInim4LdaoREQka6I8UDbAzH5sZmuBBwl6DBXGHpmIiGRFlJvFvwMeB85197pjBYmISAvXaCJw9+HZCERERHKj3kRgZk+4++VmtoYvDx8daYYyERFpGRqqEdwY/rwgG4GIiEhu1Huz2N23hW9vcPfNqS/ghuyEJyIicYvSffSbadaNynQgIiKSGw3dI7ie4Jt/XzNbnbKpAHgt7sBERCQ7GrpH8J/AH4GfA9NS1u929w9ijUpERLKmoUTg7r7JzCbX3WBmhysZiIi0Do3VCC4Aigm6j1rKNgf6xhiXiIhkSb2JwN0vCH/2yV44IiKSbVHGGjrNzA4J3/+zmf3KzHrGH5qIiGRDlO6jvwX2mNlg4IfAZuD3sUYlIiJZE3XyegcuAu5z9/sIupCKiEgrEGX00d1m9r+A8cDpZpYH5McbloiIZEuUGsEYgonrr3b394AewN2xRiUiIlkTZarK94A5QEczuwCocPfHYo9MRESyIkqvocuBZcB3gMuBv5nZZXEHJiIi2RHlHsGtwMnu/j6AmXUDXgXmxRmYiIhkR5R7BG1qkkCoPOJ+IiLSAkSpEfzJzBYQzFsMwc3jl+ILSUREsinKnMU/MLNvA18nGG9ohrs/E3tkIiKSFQ3NR9APuAf4J2ANcLO7b81WYCIikh0NtfU/ArwAXEowAukDTT24mY00s/VmVmpm0xood7KZ7VVvJBGR7GuoaajA3R8O3683s5VNOXD4BPJ0gqkuy4DlZjbf3d9IU+4XwIKmHF9ERDKjoUTQ3sxO5It5CDqkLrt7Y4nhFKDU3TcCmNlcgvGK3qhTbirwFHByE2MXEZEMaCgRbAN+lbL8XsqyA2c3cuwewJaU5TJgWGoBM+sBXBIeq95EYGaTgEkAPXtqBGwRkUxqaGKas5p5bEuzzuss3wvc4u57zdIVr41lBjADoKioqO4xRESkGaI8R7C/yoCjU5YLgXfrlCkC5oZJoCtwvplVufuzMcYlIiIp4kwEy4F+ZtYH2AqMBa5MLZA6DaaZzQZeUBIQEcmu2BKBu1eZ2RSC3kB5wCPuvs7Mrgu3PxTXuUVEJLpGE4EF7TbjgL7ufkc4X/FR7r6ssX3d/SXqDEdRXwJw9wmRIhYRkYyKMnjcb4CvAVeEy7sJng8QEZFWIErT0DB3P8nM/g7g7jvNrF3McYmISJZEqRFUhk//OtTOR1Ada1QiIpI1URLB/cAzwBFm9lPgv4GfxRqViIhkTZRhqOeYWTHwDYKHxC529zdjj0xERLIiSq+hnsAe4PnUde7+TpyBiYhIdkS5Wfwiwf0BA9oDfYD1wHExxiUiIlkSpWloUOqymZ0EXBtbRCIiklVNnoQ+HH5aQ0aLiLQSUe4R3JSy2AY4CdgeW0QiIpJVUe4RFKS8ryK4Z/BUPOGIiEi2NZgIwgfJDnX3H2QpHhERybJ67xGYWVt330vQFCQiIq1UQzWCZQRJoMTM5gNPAp/UbHT3p2OOTUREsiDKPYLDgXKCeYVrnidwQIlARKQVaCgRHBH2GFrLFwmghuYNFhFpJRpKBHnAoUSbhF5ERFqohhLBNne/I2uRiIhITjT0ZHG6moCIiLQyDSWCb2QtChERyZl6E4G7f5DNQEREJDeaPOiciIi0LkoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwsSYCMxtpZuvNrNTMpqXZPs7MVoevJWY2OM54RERkX7ElgnC+4+nAKGAgcIWZDaxT7G3gDHc/AbgTmBFXPCIikl6cNYJTgFJ33+junwNzgYtSC7j7EnffGS4uBQpjjEdERNKIMxH0ALakLJeF6+pzDfDHdBvMbJKZrTCzFdu3b89giCIiEmciiDyzmZmdRZAIbkm33d1nuHuRuxd169YtgyGKiEiUyev3VxlwdMpyIfBu3UJmdgIwExjl7uUxxiMiImnEWSNYDvQzsz5m1g4YC8xPLWBmPYGngfHuviHGWEREpB6x1QjcvcrMpgALgDzgEXdfZ2bXhdsfAm4DugC/MTOAKncviismERHZV5xNQ7j7S8BLddY9lPJ+IjAxzhhERKRherJYRCThlAhERBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThlAhERBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThlAhERBJOiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThlAhERBJOiUBEJOHa5jqAbNldUclHFVUUb97J0F6dcx2OHCAqKyspKyujoqIi16GIZET79u0pLCwkPz8/8j6JSATFm3fyj/d2U+0wbuZS5kwcrmQgAJSVlVFQUEDv3r0xs1yHI9Is7k55eTllZWX06dMn8n6JaBpaurGcag/eV1ZVs3RjeW4DkgNGRUUFXbp0URKQVsHM6NKlS5NruIlIBMP7dqFN+P88v20bhvftktuA5ICiJCCtyf78PSeiaWhor870P6qAjyqquG/siWoWEhFJkYgaAUBB+3x6dOqgJCAHHDNj/PjxtctVVVV069aNCy64AIDZs2czZcqUffbr3bs3gwYNYvDgwZx77rm89957jZ7re9/7HosXL67df8eOHfuUmT9/PnfddVfa/Q899NC06ydMmMC8efMaPX9jNm3axPHHH9/s4zTXbbfdxquvvpq18916660cffTR+/x+P/vsM8aMGcMxxxzDsGHD2LRpEwDbt29n5MiRGTt/YhKBSKYUb97J9IWlFG/emZHjHXLIIaxdu5ZPP/0UgFdeeYUePXpE2nfhwoWsWrWKoqIifvaznzVY9oMPPmDp0qWMGDGiwXIXXngh06ZNixZ8C7N3795I5e644w7OOeecmKP5wre+9S2WLVu2z/pZs2bRuXNnSktL+f73v88tt9wCQLdu3ejevTuvvfZaRs6fiKYhkShuf34db7z7UYNldldU1vZAa2PQ/6gCCtrX301v4FcO40ffOq7Rc48aNYoXX3yRyy67jMcff5wrrriCv/71r5FjHzFiBPfff3+DZebNm7fPt8gHHniA559/nsrKSp588kn69+/P7NmzWbFiBQ8++CBvv/02V155JVVVVV/a192ZOnUqf/7zn+nTpw/uXrutuLiYm266iY8//piuXbsye/ZsunfvzplnnsmwYcNYuHAhH374IbNmzeL000+vN95NmzYxfvx4PvnkEwAefPBBTj31VMaPH89ll13GRRddBMC4ceMYM2YMo0ePZtq0aSxatIjPPvuMyZMnc+2117Jo0SJuv/12unfvTklJCW+88UbtOfbu3cs111zDihUrMDOuvvpqvv/97zNhwgQuuOACevfuzcSJE2vLrl27FnfnrbfeYvLkyWzfvp2DDz6Yhx9+mP79+/Pkk09y++23k5eXR8eOHWtrX40ZPnx42vXPPfccP/7xjwG47LLLmDJlCu6OmXHxxRczZ84cTjvttEjnaIhqBCJN8FFFVW0PtGoPljNh7NixzJ07l4qKClavXs2wYcOatP8LL7zAoEGDGizz2muvMXTo0C+t69q1KytXruT666/nnnvu2WefG2+8keuvv57ly5dz1FFH1a5/5plnWL9+PWvWrOHhhx9myZIlQPBcxtSpU5k3bx7FxcVcffXV3HrrrbX7VVVVsWzZMu69915uv/32BuM94ogjeOWVV1i5ciV/+MMf+O53vwvAxIkT+d3vfgfArl27WLJkCeeffz6zZs2iY8eOLF++nOXLl/Pwww/z9ttvA7Bs2TJ++tOffikJAJSUlLB161bWrl3LmjVruOqqq760vaioiJKSEkpKShg5ciQ333wzAJMmTeKBBx6guLiYe+65hxtuuAEIahILFixg1apVzJ8/H4D169czZMiQtK8PP/ywwd/B1q1bOfroowFo27YtHTt2pLy8vDa2pnxZaIhqBCKhKN/cizfvZNzMpVRWVZPftk3GOh+ccMIJbNq0iccff5zzzz8/8n5nnXUWeXl5nHDCCfzkJz9psOy2bdvo1q3bl9Z9+9vfBmDo0KE8/fTT++zz2muv8dRTTwEwfvz42qaJxYsXc8UVV5CXl8dXvvIVzj77bCD40Fu7di3f/OY3geBbdPfu3dOer6a9uz6VlZVMmTKFkpIS8vLy2LBhAwBnnHEGkydP5v333+fpp5/m0ksvpW3btrz88susXr269l7Frl27+J//+R/atWvHKaeckrZffd++fdm4cSNTp05l9OjRnHvuuWljeeKJJ1i5ciUvv/wyH3/8MUuWLOE73/lO7fbPPvsMgNNOO40JEyZw+eWX117rscceS0lJSYPXWp/UmlaNml5BRxxxBO++++5+HbeuWBOBmY0E7gPygJnufled7RZuPx/YA0xw95VxxiTSHEN7dWbOxOEs3VjO8L5dMtr54MILL+Tmm29m0aJFtd/6GrNw4UK6du0aqWyHDh326V9+0EEHAZCXl0dVVfraTX3dEdOtd3eOO+44Xn/99bT7RDlfjV//+tcceeSRrFq1iurqatq3b1+7bfz48cyZM4e5c+fyyCOP1J77gQce4LzzzvvScRYtWsQhhxyS9hydO3dm1apVLFiwgOnTp/PEE0/UHq/GunXr+NGPfsTixYvJy8ujurqaTp06pf1wf+ihh/jb3/7Giy++yJAhQygpKWHHjh2MGTMm7fkXLVpEp06d6v0dFBYWsmXLFgoLC6mqqmLXrl0cfvjhQPAMTIcOHerdtyliaxoyszxgOjAKGAhcYWYD6xQbBfQLX5OA38YVz+6KSrZ++GnGbvBJcg3t1ZnJZx2T8R5oV199NbfddlujTTz7a8CAAZSWljZpn9NOO425c+cCMGfOnNr1I0aMYO7cuezdu5dt27axcOFCIPj2u3379tpEUFlZybp16/Yr3l27dtG9e3fatGnD73//+y/d6J0wYQL33nsvAMcdF9TkzjvvPH77299SWVkJwIYNG2rvL9Rnx44dVFdXc+mll3LnnXeycuWXv4fu2rWLsWPH8thjj9XWpg477DD69OnDk08+CQQJaNWqVQC89dZbDBs2jDvuuIOuXbuyZcuW2hpBuldDSQCCLwePPvooENzjOfvss2sT8IYNGzLWwyrOewSnAKXuvtHdPwfmAhfVKXMR8JgHlgKdzKx73QM1V80QE2U7P2XczKVKBnJAKiws5MYbb0y7bfbs2RQWFta+ysrKmnz80aNHs2jRoibtc9999zF9+nROPvlkdu3aVbv+kksuoV+/fgwaNIjrr7+eM844A4B27doxb948brnlFgYPHsyQIUNq7x801Q033MCjjz7K8OHD2bBhw5e+1R955JEMGDDgS236EydOZODAgZx00kkcf/zxXHvttY3WOrZu3cqZZ57JkCFDmDBhAj//+c+/tP3ZZ59l8+bN/Ou//mttuz4ESXHWrFkMHjyY4447jueeew6AH/zgBwwaNIjjjz+eESNGMHjw4EjX+sMf/pDCwkL27NlDYWFh7Q3ia665hvLyco455hh+9atffalb78KFCxk9enSk4zfG0rVBZeTAZpcBI919Yrg8Hhjm7lNSyrwA3OXu/x0u/xdwi7uvqHOsSQQ1Bnr27Dl08+bNTYpl+sJS7lmwHgfyDG4691gmn3VMM65OWos333yTAQMG5DqMrPn617/OCy+80Og30QPdnj17GDRoECtXrqRjx465DicnRowYwXPPPUfnzvvWTNP9XZtZsbsXpTtWnDWCdA2LdbNOlDK4+wx3L3L3oro3u6IY3rcLB+W3Ic80xIQk2y9/+UveeeedXIfRLK+++ir9+/dn6tSpiU0C27dv56abbkqbBPZHnDeLy4CjU5YLgbq3uKOUabY4b/CJtCRN7ZZ6IDrnnHNafDJrrm7dunHxxRdn7HhxJoLlQD8z6wNsBcYCV9YpMx+YYmZzgWHALnffFkcwQ3t1VgKQtGoe0BFpDfanuT+2RODuVWY2BVhA0H30EXdfZ2bXhdsfAl4i6DpaStB99Kr6jicSh/bt21NeXq6hqKVVqJmPILWrbRSx3SyOS1FRka9YsaLxgiIRaIYyaW3qm6GsoZvFerJYEi0/P79JMzmJtEYaa0hEJOGUCEREEk6JQEQk4VrczWIz2w407dHiL3QF9p2SqXXTNSeDrjkZmnPNvdw97RO5LS4RNIeZrajvrnlrpWtOBl1zMsR1zWoaEhFJOCUCEZGES1oimJHrAHJA15wMuuZkiOWaE3WPQERE9pW0GoGIiNShRCAiknCtMhGY2UgzW29mpWY2Lc12M7P7w+2rzeykXMSZSRGueVx4ravNbImZRZtD7wDW2DWnlDvZzPaGs+a1aFGu2czONLMSM1tnZn/JdoyZFuFvu6OZPW9mq8JrbtGjGJvZI2b2vpmtrWd75j+/3L1VvQiGvH4L6Au0A1YBA+uUOR/4I8EMacOBv+U67ixc86lA5/D9qCRcc0q5PxMMeX5ZruPOwr9zJ+ANoGe4fESu487CNf878IvwfTfgA6BdrmNvxjWPAE4C1tazPeOfX62xRnAKUOruG939c2AucFGdMhcBj3lgKdDJzLpnO9AMavSa3X2Ju+8MF5cSzAbXkkX5dwaYCjwFvJ/N4GIS5ZqvBJ5293cA3L2lX3eUa3agwIIJJQ4lSAQNz1p/AHP3xQTXUJ+Mf361xkTQA9iSslwWrmtqmZakqddzDcE3ipas0Ws2sx7AJcBDWYwrTlH+nb8KdDazRWZWbGb/krXo4hHlmh8EBhBMc7sGuNHdq7MTXk5k/POrNc5HkG6aqbp9ZKOUaUkiX4+ZnUWQCL4ea0Txi3LN9wK3uPveVjL7WJRrbgsMBb4BdABeN7Ol7r4h7uBiEuWazwNKgLOBfwJeMbO/uvtHcQeXIxn//GqNiaAMODpluZDgm0JTy7Qkka7HzE4AZgKj3L08S7HFJco1FwFzwyTQFTjfzKrc/dnshJhxUf+2d7j7J8AnZrYYGAy01EQQ5ZqvAu7yoAG91MzeBvoDy7ITYtZl/POrNTYNLQf6mVkfM2sHjAXm1ykzH/iX8O77cGCXu2/LdqAZ1Og1m1lP4GlgfAv+dpiq0Wt29z7u3tvdewPzgBtacBKAaH/bzwGnm1lbMzsYGAa8meU4MynKNb9DUAPCzI4EjgU2ZjXK7Mr451erqxG4e5WZTQEWEPQ4eMTd15nZdeH2hwh6kJwPlAJ7CL5RtFgRr/k2oAvwm/AbcpW34JEbI15zqxLlmt39TTP7E7AaqAZmunvabogtQcR/5zuB2Wa2hqDZ5BZ3b7HDU5vZ48CZQFczKwN+BORDfJ9fGmJCRCThWmPTkIiINIESgYhIwikRiIgknBKBiEjCKRGIiCScEoEckMLRQktSXr0bKPtxBs4328zeDs+10sy+th/HmGlmA8P3/15n25Lmxhgep+b3sjYccbNTI+WHmNn5mTi3tIXjrP4AAAO9SURBVF7qPioHJDP72N0PzXTZBo4xG3jB3eeZ2bnAPe5+QjOO1+yYGjuumT0KbHD3nzZQfgJQ5O5TMh2LtB6qEUiLYGaHmtl/hd/W15jZPiONmll3M1uc8o359HD9uWb2erjvk2bW2Af0YuCYcN+bwmOtNbPvhesOMbMXw/Hv15rZmHD9IjMrMrO7gA5hHHPCbR+HP/+Q+g09rIlcamZ5Zna3mS23YIz5ayP8Wl4nHGzMzE6xYJ6Jv4c/jw2fxL0DGBPGMiaM/ZHwPH9P93uUBMr12Nt66ZXuBewlGEisBHiG4Cn4w8JtXQmeqqyp0X4c/vw34NbwfR5QEJZdDBwSrr8FuC3N+WYTzlcAfAf4G8HgbWuAQwiGN14HnAhcCjycsm/H8Ocigm/ftTGllKmJ8RLg0fB9O4JRJDsAk4D/CNcfBKwA+qSJ8+OU63sSGBkuHwa0Dd+fAzwVvp8APJiy/8+Afw7fdyIYg+iQXP9765XbV6sbYkJajU/dfUjNgpnlAz8zsxEEQyf0AI4E3kvZZznwSFj2WXcvMbMzgIHAa+HQGu0Ivkmnc7eZ/QewnWCE1m8Az3gwgBtm9jRwOvAn4B4z+wVBc9Jfm3BdfwTuN7ODgJHAYnf/NGyOOsG+mEWtI9APeLvO/h3MrAToDRQDr6SUf9TM+hGMRJlfz/nPBS40s5vD5fZAT1r2eETSTEoE0lKMI5h9aqi7V5rZJoIPsVruvjhMFKOB35vZ3cBO4BV3vyLCOX7g7vNqFszsnHSF3H2DmQ0lGO/l52b2srvfEeUi3L3CzBYRDJ08Bni85nTAVHdf0MghPnX3IWbWEXgBmAzcTzDezkJ3vyS8sb6onv0NuNTd10eJV5JB9wikpegIvB8mgbOAXnULmFmvsMzDwCyC6f6WAqeZWU2b/8Fm9tWI51wMXBzucwhBs85fzewrwB53/3/APeF56qoMaybpzCUYKOx0gsHUCH9eX7OPmX01PGda7r4L+C5wc7hPR2BruHlCStHdBE1kNRYAUy2sHpnZifWdQ5JDiUBaijlAkZmtIKgd/CNNmTOBEjP7O0E7/n3uvp3gg/FxM1tNkBj6Rzmhu68kuHewjOCewUx3/zswCFgWNtHcCvwkze4zgNU1N4vreJlgXtpXPZh+EYJ5It4AVlowafn/pZEaexjLKoKhmf8PQe3kNYL7BzUWAgNrbhYT1Bzyw9jWhsuScOo+KiKScKoRiIgknBKBiEjCKRGIiCScEoGISMIpEYiIJJwSgYhIwikRiIgk3P8HqzcZg/lA0Z4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# generate a random prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# fit second model(MLP 2)\n",
    "clf = MLPClassifier(random_state=0, activation='logistic', hidden_layer_sizes=(10,), max_iter=100)\n",
    "clf.fit(X_train, y_train)\n",
    "lr_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate accuracy score for random prediction model\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "\n",
    "# calculate accuracy score different MLP models\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('MLP  (hidden layer sizes=10): ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='MLP  (hidden layer sizes=10)')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
